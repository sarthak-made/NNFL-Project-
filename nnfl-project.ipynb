{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport math\nimport numpy as np\n\nimport cv2\ndef calculate_scalingFactors(alpha,beta,gamma,phi):\n        depth_factor = alpha ** phi\n        width_factor = beta ** phi\n        resolution_factor = gamma ** phi\n        return depth_factor,width_factor,resolution_factor\n\nphi = 1\nalpha = 1.1\nbeta = 1.2\ngamma = 1\nd,w,r = calculate_scalingFactors(alpha,beta,gamma,phi)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:32.004969Z","iopub.execute_input":"2022-04-30T12:54:32.005291Z","iopub.status.idle":"2022-04-30T12:54:32.012250Z","shell.execute_reply.started":"2022-04-30T12:54:32.005255Z","shell.execute_reply":"2022-04-30T12:54:32.011546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:33.778465Z","iopub.execute_input":"2022-04-30T12:54:33.778990Z","iopub.status.idle":"2022-04-30T12:54:33.783425Z","shell.execute_reply.started":"2022-04-30T12:54:33.778950Z","shell.execute_reply":"2022-04-30T12:54:33.782615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:34.748287Z","iopub.execute_input":"2022-04-30T12:54:34.748797Z","iopub.status.idle":"2022-04-30T12:54:34.760125Z","shell.execute_reply.started":"2022-04-30T12:54:34.748759Z","shell.execute_reply":"2022-04-30T12:54:34.759389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nnum_classes = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:35.381965Z","iopub.execute_input":"2022-04-30T12:54:35.382652Z","iopub.status.idle":"2022-04-30T12:54:35.386594Z","shell.execute_reply.started":"2022-04-30T12:54:35.382617Z","shell.execute_reply":"2022-04-30T12:54:35.385429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_transforms = transforms.Compose([\n                                transforms.Resize(math.ceil(32*r)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) \n])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:36.258956Z","iopub.execute_input":"2022-04-30T12:54:36.259755Z","iopub.status.idle":"2022-04-30T12:54:36.264022Z","shell.execute_reply.started":"2022-04-30T12:54:36.259709Z","shell.execute_reply":"2022-04-30T12:54:36.263472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=all_transforms, download='True')\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=all_transforms, download='True')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:36.991058Z","iopub.execute_input":"2022-04-30T12:54:36.991403Z","iopub.status.idle":"2022-04-30T12:54:45.409845Z","shell.execute_reply.started":"2022-04-30T12:54:36.991368Z","shell.execute_reply":"2022-04-30T12:54:45.409145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:45.411295Z","iopub.execute_input":"2022-04-30T12:54:45.411569Z","iopub.status.idle":"2022-04-30T12:54:45.417124Z","shell.execute_reply.started":"2022-04-30T12:54:45.411541Z","shell.execute_reply":"2022-04-30T12:54:45.416236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    \n    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n        super(ResBlock, self).__init__()\n        \"\"\"\n        1. kernel_size = 3 and padding = 1 for both conv layers\n        2. use the argument stride for conv1 layer and stride=1 for conv2 layer\n        3. input channels = in_channels and output channels = out_channels for conv1\n        4. input and output channels = out_channels for conv2\n        \"\"\"\n        ### YOUR CODE HERE ###\n        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, dilation=1)\n        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1)\n        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n        self.relu = torch.nn.ReLU()\n        ### ENDS HERE ###\n        \"\"\"\n        We'll need identity_downsample when the dimensions f(x), i.e., output of\n        step2 is not the same as x\n        \"\"\"\n        self.identity_downsample = identity_downsample\n        \n        \n    def forward(self, x):\n        ### YOUR CODE HERE ###\n        #step 1\n        identity = x\n        #step2\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n\n\n        #do not modify this if condition, change your variable names accordingly\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n        #step3\n        x = x + identity\n        #step4\n        x = self.relu(x)\n        \n        ### ENDS HERE ###\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:47.416362Z","iopub.execute_input":"2022-04-30T12:54:47.416635Z","iopub.status.idle":"2022-04-30T12:54:47.429498Z","shell.execute_reply.started":"2022-04-30T12:54:47.416604Z","shell.execute_reply":"2022-04-30T12:54:47.428404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet18(nn.Module):\n    # d is the depth scaling factor, whereas w is the width scaling factor\n    def __init__(self, image_channels, num_classes,d,r,w):\n        \n        \n        super(ResNet18, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, int(64*w) , kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(int(64*w)) \n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n       #Width scaling by a factor means increasing the no of channels i.e. no of filters across each ResBlock\n        self.layer1 = self.make_layer(int(64*w), int(64*w), 1,d)\n        self.layer2 = self.make_layer(int(64*w), int(128*w), 2,d)\n        self.layer3 = self.make_layer(int(128*w), int(256*w), 2,d)\n        self.layer4 = self.make_layer(int(256*w), int(512*w), 2,d)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        #Aladdin uses a last channels variable we directly code it as 512*w\n        self.fc = nn.Linear(int(512*w), num_classes)\n\n        \n    def make_layer(self, in_channels, out_channels, stride, depth_scaling):\n        identity_downsample = None\n        repeats = 2\n        layer_repeat = math.ceil(depth_scaling*repeats)\n        if stride != 1:\n            identity_downsample = self.identity_downsample(in_channels, out_channels)\n\n        \"\"\"\n        Call `ResBlock` here.  You already have info about all the arguments \n        that needs to be passed to ResBlock.\n        Hint1: use nn.Sequential to make one layer.\n        Hint2: you will need two ResBlocks to make one layer\n        \"\"\"\n        '''\n        DOUBT: We need identity downsample even when stride != 1\n        also same downsampler for both resnet blocks? don't they have different input size?\n        also def identity_downsample(self, in_channels, out_channels): does not have stride? (so I just wrote the code directly up above)\n        '''\n        #model =  nn.Sequential(\n        #    ResBlock(in_channels, out_channels, identity_downsample, stride),\n        #    ResBlock(out_channels, out_channels) \n        #)\n        \n#         model = nn.Sequential(ResBlock(in_channels,out_channels,identity_downsample,stride))\n#         for i in range(layer_repeat-1):\n#             model.append(ResBlock(out_channels,out_channels))\n#         return model\n\n        model = nn.Sequential(ResBlock(in_channels,out_channels,identity_downsample,stride))\n        for i in range(layer_repeat-1):\n            nn.Sequential(model, ResBlock(out_channels,out_channels))\n        return model\n#         model = [ResBlock(in_channels,out_channels,identity_downsample,stride)]\n#         for i in range(layer_repeat-1):\n#             model.append(ResBlock(out_channels,out_channels))\n#          return nn.Sequential(*model)   \n        \n\n    def identity_downsample(self, in_channels, out_channels):\n        \n        return nn.Sequential(\n                nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=2,padding=1),\n                nn.BatchNorm2d(out_channels)\n            ) \n    \n    def calculate_scalingFactors(self, alpha,beta,phi):\n        depth_factor = alpha ** phi\n        width_factor = beta ** phi\n        return depth_factor,width_factor\n        \n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        x = self.avgpool(x)\n        x = x.view(x.shape[0], -1)\n        x = self.fc(x)\n        return x ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:49.476547Z","iopub.execute_input":"2022-04-30T12:54:49.476814Z","iopub.status.idle":"2022-04-30T12:54:49.497452Z","shell.execute_reply.started":"2022-04-30T12:54:49.476783Z","shell.execute_reply":"2022-04-30T12:54:49.496410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(0)\nmodel = ResNet18(3, num_classes,d,r,w)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:50.744797Z","iopub.execute_input":"2022-04-30T12:54:50.745075Z","iopub.status.idle":"2022-04-30T12:54:50.993827Z","shell.execute_reply.started":"2022-04-30T12:54:50.745048Z","shell.execute_reply":"2022-04-30T12:54:50.992938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.001\nnum_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:56.143633Z","iopub.execute_input":"2022-04-30T12:54:56.143927Z","iopub.status.idle":"2022-04-30T12:54:56.148364Z","shell.execute_reply.started":"2022-04-30T12:54:56.143898Z","shell.execute_reply":"2022-04-30T12:54:56.147659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\n# Set optimizer with optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n\ntotal_step = len(train_loader)\n#print(total_step)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:57.772009Z","iopub.execute_input":"2022-04-30T12:54:57.772288Z","iopub.status.idle":"2022-04-30T12:54:57.778399Z","shell.execute_reply.started":"2022-04-30T12:54:57.772261Z","shell.execute_reply":"2022-04-30T12:54:57.777366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.manual_seed(0)\n# for epoch in range(num_epochs):\n# \t#Load in the data in batches using the train_loader object\n#     for i, (images, labels) in enumerate(train_loader):  \n#         # Move tensors to the configured device\n#         images = images.to(device)\n#         labels = labels.to(device)\n        \n#         # Forward pass\n#         outputs = model(images)\n#         loss = criterion(outputs, labels)\n        \n#         # Backward and optimize\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#     print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:24:45.901451Z","iopub.execute_input":"2022-04-30T08:24:45.901831Z","iopub.status.idle":"2022-04-30T08:24:45.909176Z","shell.execute_reply.started":"2022-04-30T08:24:45.901795Z","shell.execute_reply":"2022-04-30T08:24:45.908558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with torch.no_grad():\n#     correct = 0\n#     total = 0\n#     for images, labels in train_loader:\n#         images = images.to(device)\n#         labels = labels.to(device)\n#         outputs = model(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n    \n#     print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:24:45.912078Z","iopub.execute_input":"2022-04-30T08:24:45.912278Z","iopub.status.idle":"2022-04-30T08:24:45.92093Z","shell.execute_reply.started":"2022-04-30T08:24:45.912255Z","shell.execute_reply":"2022-04-30T08:24:45.920129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with torch.no_grad():\n#     correct = 0\n#     total = 0\n#     for images, labels in test_loader:\n#         images = images.to(device)\n#         labels = labels.to(device)\n#         outputs = model(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n    \n#     print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:24:45.921959Z","iopub.execute_input":"2022-04-30T08:24:45.922219Z","iopub.status.idle":"2022-04-30T08:24:45.929502Z","shell.execute_reply.started":"2022-04-30T08:24:45.922184Z","shell.execute_reply":"2022-04-30T08:24:45.928675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nn = NeuralNetClassifier(ResNet18, verbose=0, train_split=False)\nalpha_arr = np.linspace(1,2,7)\nbeta_arr = np.linspace(1,2,7)\ngamma_arr = np.linspace(1,2,7)\n#param_grid = dict(nn__module__image_channels = [3], nn__module__num_classes = [10],nn__module__d = alpha_arr,nn__module__r = beta_arr,nn__module__w = gamma_arr)\n#accuracy = EpochScoring(scoring='accuracy', lower_is_better=False)\n#grid  = GridSearchCV(estimator = nn , param_grid = param_grid,scoring='accuracy',verbose =1)\n\n#grid.fit(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:55:04.876669Z","iopub.execute_input":"2022-04-30T12:55:04.876931Z","iopub.status.idle":"2022-04-30T12:55:04.882567Z","shell.execute_reply.started":"2022-04-30T12:55:04.876904Z","shell.execute_reply":"2022-04-30T12:55:04.881737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = []\n# y = []\n# for i in range(train_dataset.__len__()):\n#     x.append(train_dataset.__getitem__(i)[0])\n#     y.append(train_dataset.__getitem__(i)[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:55:06.210478Z","iopub.execute_input":"2022-04-30T12:55:06.211244Z","iopub.status.idle":"2022-04-30T12:55:06.215133Z","shell.execute_reply.started":"2022-04-30T12:55:06.211202Z","shell.execute_reply":"2022-04-30T12:55:06.214205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\n# Set optimizer with optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n\ntotal_step = len(train_loader)\n#print(total_step)\n\nresults = []\n#file = open(r\"gridsearch.txt\",'a')\n#file.write(\"GridSearch Data alpha beta gamma and accuracy\")\nfor i_out in range(7):\n    for j in range(7):\n        for k in range(7):\n            #print(i j k)\n            model = ResNet18(3, num_classes,alpha_arr[i_out],beta_arr[j],gamma_arr[k])\n            model.to(device)\n            torch.manual_seed(0)\n            for epoch in range(num_epochs):\n                for i, (images, labels) in enumerate(train_loader):\n                    images = images.to(device)\n                    labels = labels.to(device)\n\n                    # Forward pass\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n\n                    # Backward and optimize\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n                \n            with torch.no_grad():\n                correct = 0\n                total = 0\n                for images, labels in train_loader:\n                    images = images.to(device)\n                    labels = labels.to(device)\n                    outputs = model(images)\n                    _, predicted = torch.max(outputs.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n            print(alpha_arr[i_out],beta_arr[j],gamma_arr[k],100 * correct / total)\n            #file.write(alpha_arr[i_out],beta_arr[j],gamma_arr[k],100 * correct / total)\n            results.append([alpha_arr[i_out],beta_arr[j],gamma_arr[k],100 * correct / total])\n            \n#file.close()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:55:07.511005Z","iopub.execute_input":"2022-04-30T12:55:07.511625Z","iopub.status.idle":"2022-04-30T12:56:34.826476Z","shell.execute_reply.started":"2022-04-30T12:55:07.511588Z","shell.execute_reply":"2022-04-30T12:56:34.825031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:56:34.830463Z","iopub.status.idle":"2022-04-30T12:56:34.830929Z","shell.execute_reply.started":"2022-04-30T12:56:34.830756Z","shell.execute_reply":"2022-04-30T12:56:34.830775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}